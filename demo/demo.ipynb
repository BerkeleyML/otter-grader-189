{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otter-Grader Demo Notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use otter-grader. For installation details, see the [README](https://github.com/ucbds-infra/otter-grader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from subprocess import PIPE\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebooks\n",
    "\n",
    "Otter supports in-notebook checks so that students can check their progress when working through an assignments. To use it, you need to create an instance of `otter.Notebook`, to which you (optionally) pass a path to a directory of tests; this defaults to `./tests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check a student's work, use `Notebook.check`. Pass to this the question identifier, which is the filename (without the `.py` extension). For example, in this demo, `./tests/q4.py` tests a student's `square` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test = {\n",
      "\t\"name\": \"q4\",\n",
      "\t\"points\": 1,\n",
      "\t\"suites\": [ \n",
      "\t\t{\n",
      "\t\t\t\"cases\": [ \n",
      "\t\t\t\t{\n",
      "\t\t\t\t\t\"code\": r\"\"\"\n",
      "\t\t\t\t\t>>> square(5)\n",
      "\t\t\t\t\t25\n",
      "\t\t\t\t\t>>> square(2.5)\n",
      "\t\t\t\t\t6.25\n",
      "\t\t\t\t\t\"\"\"\n",
      "\t\t\t\t},\n",
      "\t\t\t],\n",
      "\t\t\t\"scored\": False,\n",
      "\t\t\t\"setup\": \"\",\n",
      "\t\t\t\"teardown\": \"\",\n",
      "\t\t\t\"type\": \"doctest\"\n",
      "\t\t}, \n",
      "\t]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./tests/q4.py\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have the square function defined below, we can run the test using `grader.check(\"q4\")`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "<otter.gofer.OKTestsResult at 0x119549748>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the function so that the tests fail, then the grader outputs the failed test and the incorrect output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>0 of 1 tests passed</p>\n",
       "        \n",
       "        \n",
       "        <p> <strong>Tests failed: </strong>\n",
       "            <ul>\n",
       "            \n",
       "                <li> \n",
       "    <p><strong style='color: red;'>./tests/q4.py</strong></p>\n",
       "    <p><strong>Test code:</strong><pre><div class=\"highlight\" style=\"background: #f8f8f8\"><pre style=\"line-height: 125%\"><span></span><span style=\"color: #000080; font-weight: bold\">&gt;&gt;&gt; </span>square(<span style=\"color: #666666\">5</span>)\n",
       "<span style=\"color: #888888\">25</span>\n",
       "<span style=\"color: #000080; font-weight: bold\">&gt;&gt;&gt; </span>square(<span style=\"color: #666666\">2.5</span>)\n",
       "<span style=\"color: #888888\">6.25</span>\n",
       "</pre></div>\n",
       "</pre></p>\n",
       "    <p><strong>Test result:</strong><pre>Trying:\n",
       "    square(5)\n",
       "Expecting:\n",
       "    25\n",
       "**********************************************************************\n",
       "Line 2, in ./tests/q4.py 0\n",
       "Failed example:\n",
       "    square(5)\n",
       "Expected:\n",
       "    25\n",
       "Got:\n",
       "    125\n",
       "Trying:\n",
       "    square(2.5)\n",
       "Expecting:\n",
       "    6.25\n",
       "**********************************************************************\n",
       "Line 4, in ./tests/q4.py 0\n",
       "Failed example:\n",
       "    square(2.5)\n",
       "Expected:\n",
       "    6.25\n",
       "Got:\n",
       "    15.625\n",
       "</pre></p>\n",
       "     </li>\n",
       "            \n",
       "            </ul>\n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "<otter.gofer.OKTestsResult at 0x119a6b6d8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square = lambda x: x**3\n",
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students can also run all tests at once using `Notebook.check_all`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong>q1</strong></p>\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>q2</strong></p>\n",
       "    \n",
       "    \n",
       "        <p>0 of 1 tests passed</p>\n",
       "        \n",
       "        \n",
       "        <p> <strong>Tests failed: </strong>\n",
       "            <ul>\n",
       "            \n",
       "                <li> \n",
       "    <p><strong style='color: red;'>./tests/q2.py</strong></p>\n",
       "    <p><strong>Test code:</strong><pre><div class=\"highlight\" style=\"background: #f8f8f8\"><pre style=\"line-height: 125%\"><span></span><span style=\"color: #000080; font-weight: bold\">&gt;&gt;&gt; </span><span style=\"color: #666666\">1</span> <span style=\"color: #666666\">==</span> <span style=\"color: #666666\">1</span>\n",
       "<span style=\"color: #888888\">False</span>\n",
       "</pre></div>\n",
       "</pre></p>\n",
       "    <p><strong>Test result:</strong><pre>Trying:\n",
       "    1 == 1\n",
       "Expecting:\n",
       "    False\n",
       "**********************************************************************\n",
       "Line 2, in ./tests/q2.py 0\n",
       "Failed example:\n",
       "    1 == 1\n",
       "Expected:\n",
       "    False\n",
       "Got:\n",
       "    True\n",
       "</pre></p>\n",
       "     </li>\n",
       "            \n",
       "            </ul>\n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>q3</strong></p>\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>q4</strong></p>\n",
       "    \n",
       "    \n",
       "        <p>0 of 1 tests passed</p>\n",
       "        \n",
       "        \n",
       "        <p> <strong>Tests failed: </strong>\n",
       "            <ul>\n",
       "            \n",
       "                <li> \n",
       "    <p><strong style='color: red;'>./tests/q4.py</strong></p>\n",
       "    <p><strong>Test code:</strong><pre><div class=\"highlight\" style=\"background: #f8f8f8\"><pre style=\"line-height: 125%\"><span></span><span style=\"color: #000080; font-weight: bold\">&gt;&gt;&gt; </span>square(<span style=\"color: #666666\">5</span>)\n",
       "<span style=\"color: #888888\">25</span>\n",
       "<span style=\"color: #000080; font-weight: bold\">&gt;&gt;&gt; </span>square(<span style=\"color: #666666\">2.5</span>)\n",
       "<span style=\"color: #888888\">6.25</span>\n",
       "</pre></div>\n",
       "</pre></p>\n",
       "    <p><strong>Test result:</strong><pre>Trying:\n",
       "    square(5)\n",
       "Expecting:\n",
       "    25\n",
       "**********************************************************************\n",
       "Line 2, in ./tests/q4.py 0\n",
       "Failed example:\n",
       "    square(5)\n",
       "Expected:\n",
       "    25\n",
       "Got:\n",
       "    125\n",
       "Trying:\n",
       "    square(2.5)\n",
       "Expecting:\n",
       "    6.25\n",
       "**********************************************************************\n",
       "Line 4, in ./tests/q4.py 0\n",
       "Failed example:\n",
       "    square(2.5)\n",
       "Expected:\n",
       "    6.25\n",
       "Got:\n",
       "    15.625\n",
       "</pre></p>\n",
       "     </li>\n",
       "            \n",
       "            </ul>\n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><strong>q5</strong></p>\n",
       "    \n",
       "    \n",
       "        <p>0 of 1 tests passed</p>\n",
       "        \n",
       "        \n",
       "        <p> <strong>Tests failed: </strong>\n",
       "            <ul>\n",
       "            \n",
       "                <li> \n",
       "    <p><strong style='color: red;'>./tests/q5.py</strong></p>\n",
       "    <p><strong>Test code:</strong><pre><div class=\"highlight\" style=\"background: #f8f8f8\"><pre style=\"line-height: 125%\"><span></span><span style=\"color: #000080; font-weight: bold\">&gt;&gt;&gt; </span>negate(<span style=\"color: #666666\">1</span> <span style=\"color: #666666\">==</span> <span style=\"color: #666666\">1</span>)\n",
       "<span style=\"color: #888888\">False</span>\n",
       "<span style=\"color: #000080; font-weight: bold\">&gt;&gt;&gt; </span>negate(<span style=\"color: #008000\">True</span> <span style=\"color: #666666\">^</span> <span style=\"color: #008000\">False</span>)\n",
       "<span style=\"color: #888888\">False</span>\n",
       "<span style=\"color: #000080; font-weight: bold\">&gt;&gt;&gt; </span>negate(<span style=\"color: #008000\">True</span> <span style=\"color: #666666\">^</span> <span style=\"color: #008000\">True</span>)\n",
       "<span style=\"color: #888888\">True</span>\n",
       "</pre></div>\n",
       "</pre></p>\n",
       "    <p><strong>Test result:</strong><pre>Trying:\n",
       "    negate(1 == 1)\n",
       "Expecting:\n",
       "    False\n",
       "**********************************************************************\n",
       "Line 2, in ./tests/q5.py 0\n",
       "Failed example:\n",
       "    negate(1 == 1)\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/doctest.py\", line 1330, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest ./tests/q5.py 0[0]>\", line 1, in <module>\n",
       "        negate(1 == 1)\n",
       "    NameError: name 'negate' is not defined\n",
       "Trying:\n",
       "    negate(True ^ False)\n",
       "Expecting:\n",
       "    False\n",
       "**********************************************************************\n",
       "Line 4, in ./tests/q5.py 0\n",
       "Failed example:\n",
       "    negate(True ^ False)\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/doctest.py\", line 1330, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest ./tests/q5.py 0[1]>\", line 1, in <module>\n",
       "        negate(True ^ False)\n",
       "    NameError: name 'negate' is not defined\n",
       "Trying:\n",
       "    negate(True ^ True)\n",
       "Expecting:\n",
       "    True\n",
       "**********************************************************************\n",
       "Line 6, in ./tests/q5.py 0\n",
       "Failed example:\n",
       "    negate(True ^ True)\n",
       "Exception raised:\n",
       "    Traceback (most recent call last):\n",
       "      File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/doctest.py\", line 1330, in __run\n",
       "        compileflags, 1), test.globs)\n",
       "      File \"<doctest ./tests/q5.py 0[2]>\", line 1, in <module>\n",
       "        negate(True ^ True)\n",
       "    NameError: name 'negate' is not defined\n",
       "</pre></p>\n",
       "     </li>\n",
       "            \n",
       "            </ul>\n",
       "        \n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Students can also create their own PDF submissions using `Notebook.export`, to which you pass the path to the notebook. Otter uses nb2pdf to generate PDFs (more info [below](#nb2pdf)). The filtering behavior of nb2pdf is turned on by default, although it can be turned off using the `filtering=False` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t<p>Your file has been exported. Download it \n",
       "\t\t<a href=\"demo.pdf\" target=\"_blank\">here</a>!\n",
       "\t\t"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grader.export(\"demo.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripts\n",
    "\n",
    "If a student is working with Python scripts instead of notebooks, the otter command line utility has a `check` command that can run these tests as well. The help entry for this command is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: otter [-h] [-q QUESTION] [-t TESTS-PATH] file\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  file           Python file to grade\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help     show this help message and exit\r\n",
      "  -q QUESTION    Grade a specific test\r\n",
      "  -t TESTS-PATH  Path to test files\r\n"
     ]
    }
   ],
   "source": [
    "!otter check -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to run a single check, we would pass the question identifier (the filename without `.py`) to the `-q` flag. The tests path is assumed to be `./tests` unless another path is provided to the `-t` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\r\n"
     ]
    }
   ],
   "source": [
    "!otter check scripts/file0.py -q q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with notebooks, a failed test will output the test and the incorrect output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 2 tests passed\r\n",
      "\r\n",
      "Tests passed:\r\n",
      " possible \r\n",
      "\r\n",
      "\r\n",
      "Tests failed: \r\n",
      "*********************************************************************\r\n",
      "Line 2, in tests/q2.py 0\r\n",
      "Failed example:\r\n",
      "    1 == 1\r\n",
      "Expected:\r\n",
      "    False\r\n",
      "Got:\r\n",
      "    True\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!otter check scripts/file0.py -q q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check all of the tests at once, use `otter check` without a `-q` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 of 6 tests passed\r\n",
      "\r\n",
      "Tests passed:\r\n",
      " q1  q3  q4  q5 \r\n",
      "\r\n",
      "\r\n",
      "Tests failed: \r\n",
      "*********************************************************************\r\n",
      "Line 2, in tests/q2.py 0\r\n",
      "Failed example:\r\n",
      "    1 == 1\r\n",
      "Expected:\r\n",
      "    False\r\n",
      "Got:\r\n",
      "    True\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!otter check scripts/file0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebooks\n",
    "\n",
    "Otter uses Docker containers to execute students' submissions in parallel containers. It accepts exports from Gradescope and Canvas, or the notebook files with a JSON- or YAML-formatted metadata file. If you're using the custom metadata file, it requires an entry for each notebook, with the notebook filename as the `filename` parameter and the student identifier as `identifier`. An example of the YAML metadata can be found in `manual-test/meta.yml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- identifier: 0\n",
      "  filename: test-nb-0.ipynb\n",
      "- identifier: 1\n",
      "  filename: test-nb-1.ipynb\n",
      "- identifier: 2\n",
      "  filename: test-nb-2.ipynb\n",
      "- identifier: 3\n",
      "  filename: test-nb-3.ipynb\n",
      "- identifier: 4\n",
      "  filename: test-nb-4.ipynb\n"
     ]
    }
   ],
   "source": [
    "with open(\"./manual-test/meta.yml\") as f:\n",
    "    for l in f.readlines()[0:10]:\n",
    "        print(l[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements\n",
    "\n",
    "The docker container comes with the following packages installed:\n",
    "\n",
    "* datascience\n",
    "* jupyter_client\n",
    "* ipykernel\n",
    "* matplotlib\n",
    "* pandas\n",
    "* ipywidgets\n",
    "* scipy\n",
    "* nb2pdf\n",
    "* otter-grader\n",
    "\n",
    "If you have any other requirements besides these, create a `requirements.txt` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqdm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"./requirements.txt\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command-Line Usage\n",
    "\n",
    "Now let's examine the usage of the `otter` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: otter [-h] [-p NOTEBOOKS-PATH] [-t TESTS-PATH] [-o OUTPUT-PATH] [-g]\r\n",
      "             [-c] [-j JSON] [-y YAML] [-s] [--pdf] [--filter-pdf] [-v]\r\n",
      "             [-r REQUIREMENTS] [--containers NUM-CONTAINERS] [--image IMAGE]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -p NOTEBOOKS-PATH, --path NOTEBOOKS-PATH\r\n",
      "                        Path to directory of submissions\r\n",
      "  -t TESTS-PATH, --tests-path TESTS-PATH\r\n",
      "                        Path to directory of tests\r\n",
      "  -o OUTPUT-PATH, --output-path OUTPUT-PATH\r\n",
      "                        Path to which to write output\r\n",
      "  -g, --gradescope      Flag for Gradescope export\r\n",
      "  -c, --canvas          Flag for Canvas export\r\n",
      "  -j JSON, --json JSON  Flag for path to JSON metadata\r\n",
      "  -y YAML, --yaml YAML  Flag for path to YAML metadata\r\n",
      "  -s, --scripts         Flag to incidicate grading Python scripts\r\n",
      "  --pdf                 Create unfiltered PDFs for manual grading\r\n",
      "  --filter-pdf          Create filtered PDF for manual grading\r\n",
      "  -v, --verbose         Flag for verbose output\r\n",
      "  -r REQUIREMENTS, --requirements REQUIREMENTS\r\n",
      "                        Flag for Python requirements file path\r\n",
      "  --containers NUM-CONTAINERS\r\n",
      "                        Specify number of containers to run in parallel\r\n",
      "  --image IMAGE         Custom docker image to run on\r\n"
     ]
    }
   ],
   "source": [
    "!otter -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `-p` flag should be the path to the directory that conains the notebooks (or the unzipped export from Canvas or Gradescope). The `g`, `c`, `y`, and `j` flags indicate the metadata type; the `y` and `j` flags require an argument that indicates the path to the metadata file. If you want to generate PDFs for manual grading, you can add the `--pdf` or `--filter-pdf` flags, which generate an unfiltered or filtered, respectively, PDF for each notebook. If you need a requirements file, pass that path to the `-r` flag. Optionally, you can set the number of docker containers or the docker image that the grader runs on using the `--containers` and `--image` flags, respectively.\n",
    "\n",
    "Some flag defaults are listed below. If a flag is not list, it has no default value.\n",
    "\n",
    "| Flag | Default |\n",
    "|-----|-----|\n",
    "| `-p` | `./` |\n",
    "| `-t` | `./tests` |\n",
    "| `-o` | `./` |\n",
    "| `--containers` | 4 |\n",
    "| `--image` | `ucbdsinfra/otter-grader` |\n",
    "\n",
    "**If your notebooks require any other files (e.g. data files)**, place these files into the notebooks path directory (whatever the value of `-p` is). These will automatically be copied into the docker containers.\n",
    "\n",
    "Let's run the autograder on the files in `./notebooks`. The command below tells otter that our metadata file can be found at `./notebooks/meta.yml`, that the notebooks can be found in `./notebooks`, that we have a requirements file at `./requirements.txt`, and to use verbose output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found YAML metadata...\n",
      "Launching docker containers...\n",
      "Launched container ea9031b991d4...\n",
      "Launched container a66d5f51c747...\n",
      "Launched container c0acb5938062...\n",
      "Launched container cd22cc716f86...\n",
      "Installing requirements in container ea9031b991d4...\n",
      "Installing requirements in container a66d5f51c747...\n",
      "Installing requirements in container cd22cc716f86...\n",
      "Installing requirements in container c0acb5938062...\n",
      "Grading notebooks in container ea9031b991d4...\n",
      "Grading notebooks in container a66d5f51c747...\n",
      "Grading notebooks in container cd22cc716f86...\n",
      "Grading notebooks in container c0acb5938062...\n",
      "Copying grades from container a66d5f51c747...\n",
      "Copying grades from container ea9031b991d4...\n",
      "Copying grades from container c0acb5938062...\n",
      "Stopping container a66d5f51c747...\n",
      "Stopping container ea9031b991d4...\n",
      "Copying grades from container cd22cc716f86...\n",
      "Stopping container c0acb5938062...\n",
      "Stopping container cd22cc716f86...\n",
      "Combining grades and saving...\n"
     ]
    }
   ],
   "source": [
    "!otter -y notebooks/meta.yml -p notebooks -r requirements.txt -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have a CSV file with the scores and score breakdowns at `./final_grades.csv` (since we left `-o` with its default value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>file</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>q4</th>\n",
       "      <th>q5</th>\n",
       "      <th>total</th>\n",
       "      <th>possible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>test-nb-11.ipynb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>test-nb-2.ipynb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>test-nb-9.ipynb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>test-nb-52.ipynb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>test-nb-55.ipynb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifier              file   q1   q2   q3   q4   q5  total  possible\n",
       "0          11  test-nb-11.ipynb  1.0  0.0  1.0  0.0  0.0    2.0         5\n",
       "1           2   test-nb-2.ipynb  1.0  0.0  1.0  0.0  0.0    2.0         5\n",
       "2           9   test-nb-9.ipynb  1.0  0.0  1.0  0.0  0.0    2.0         5\n",
       "3          52  test-nb-52.ipynb  1.0  0.0  1.0  0.0  0.0    2.0         5\n",
       "4          55  test-nb-55.ipynb  1.0  0.0  1.0  0.0  0.0    2.0         5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"final_grades.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the autograder ran correctly, all of the submissions should receive a 2/5, since three of the tests are written to fail on these notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nb2pdf\n",
    "\n",
    "When exporting notebook PDFs, otter uses the library nb2pdf, which in turn relies on nbpdfexporter. This requires that chromium be installed on the docker container (which is true if using `ucbdsinfra/otter-grader`, the default image) but it also must be installed on the JupyterHub distribution that students use if they are going to be exporting PDFs themselves.\n",
    "\n",
    "When generating the PDF (if filtering is turned on, either by use of the `--filter-pdf` flag or `filtering=True` in `Notebook.export`), the following cells will be included by default:\n",
    "\n",
    "* Markdown cells\n",
    "* Code cells with images in the output\n",
    "* All cells tagged with `include`\n",
    "\n",
    "If a cell falls within one of the 3 categories listed above but you do not want to include it in the exported PDF, tag the cell with `ignore`. This cell will then not be added to the manual graded PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripts\n",
    "\n",
    "Otter can also grade Python scripts using the addition of the `-s` flag. It uses the same metadata and path structure as with notebooks, so the only change to our call above will be to change the path to `./scripts`. *This will overwrite `final_grades.csv` from above since we aren't changing the output path.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found YAML metadata...\n",
      "Launching docker containers...\n",
      "Launched container 44337f32f86d...\n",
      "Launched container a2079bc0d4e5...\n",
      "Launched container d73dd8be994f...\n",
      "Launched container 31c40d6c813e...\n",
      "Installing requirements in container 44337f32f86d...\n",
      "Installing requirements in container a2079bc0d4e5...\n",
      "Installing requirements in container 31c40d6c813e...\n",
      "Installing requirements in container d73dd8be994f...\n",
      "Grading scripts in container 44337f32f86d...\n",
      "Grading scripts in container a2079bc0d4e5...\n",
      "Grading scripts in container d73dd8be994f...\n",
      "Grading scripts in container 31c40d6c813e...\n",
      "Copying grades from container 44337f32f86d...\n",
      "Copying grades from container a2079bc0d4e5...\n",
      "Stopping container 44337f32f86d...\n",
      "Copying grades from container 31c40d6c813e...\n",
      "Stopping container a2079bc0d4e5...\n",
      "Copying grades from container d73dd8be994f...\n",
      "Stopping container 31c40d6c813e...\n",
      "Stopping container d73dd8be994f...\n",
      "Combining grades and saving...\n"
     ]
    }
   ],
   "source": [
    "!otter -sy scripts/meta.yml -p scripts -r requirements.txt -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should be able to read in the grades from the scripts. If all went well, they should each have a 4/5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>file</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "      <th>q4</th>\n",
       "      <th>q5</th>\n",
       "      <th>total</th>\n",
       "      <th>possible</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>file12.py</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84</td>\n",
       "      <td>file84.py</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>file78.py</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>file71.py</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>file28.py</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifier       file   q1   q2   q3   q4   q5  total  possible\n",
       "0          12  file12.py  1.0  0.0  1.0  1.0  1.0    4.0         5\n",
       "1          84  file84.py  1.0  0.0  1.0  1.0  1.0    4.0         5\n",
       "2          78  file78.py  1.0  0.0  1.0  1.0  1.0    4.0         5\n",
       "3          71  file71.py  1.0  0.0  1.0  1.0  1.0    4.0         5\n",
       "4          28  file28.py  1.0  0.0  1.0  1.0  1.0    4.0         5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"final_grades.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradescope\n",
    "\n",
    "Otter is compatible with the Gradescope autograder, and has a command line tool to generate the zipfile that is used to configure the Docker container that Gradescope's autograder usage. The base command for this utility is `otter gen`, and its help entry is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: otter [-h] [-t [TESTS-PATH]] [-o [OUTPUT-PATH]] [-r [REQUIREMENTS]]\r\n",
      "             [files [files ...]]\r\n",
      "\r\n",
      "Generates zipfile to configure Gradescope autograder\r\n",
      "\r\n",
      "positional arguments:\r\n",
      "  files                 Other support files needed for grading (e.g. .py\r\n",
      "                        files, data files)\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -t [TESTS-PATH], --tests-path [TESTS-PATH]\r\n",
      "                        Path to test files\r\n",
      "  -o [OUTPUT-PATH], --output-path [OUTPUT-PATH]\r\n",
      "                        Path to which to write zipfile\r\n",
      "  -r [REQUIREMENTS], --requirements [REQUIREMENTS]\r\n",
      "                        Path to requirements.txt file\r\n"
     ]
    }
   ],
   "source": [
    "!otter gen -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `otter gen` command creates a zipfile at `OUTPUT-PATH/autograder.zip` which contains the necessary files for the Gradescope autograder:\n",
    "\n",
    "* `run_autograder`: the script that executes otter\n",
    "* `setup.sh`: a file that instructs Ubuntu on how to install dependencies\n",
    "* `requirements.txt`: Python's list of necessary dependencies\n",
    "* `tests`: the folder of test cases\n",
    "* `files`: a folder containing any files needed for the notebooks to execute (e.g. data files)\n",
    "\n",
    "The requirements file create automatically includes the otter dependencies (see [Requirements](#Requirements)), but you can optionally include your own, other ones by passing a filepath to the `-r` flag. Any files included that are not passed to a flag are automatically placed into the `files` folder in the zipfile and will be copied into the notebook directory in the Gradescope container.\n",
    "\n",
    "Let's generate a zipfile from this directory with the tests in `./tests`, the requirements in `./requirements.txt`, and `test-df.csv` as a data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!otter gen -r requirements.txt test-df.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a file `./autograder.zip` in the working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"autograder.zip\" in os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we unzip the file, you'll see all of the files listed above as well as the CSV file we added in the `autograder/files` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  autograder.zip\n",
      "  inflating: autograder/run_autograder  \n",
      "  inflating: autograder/setup.sh     \n",
      "  inflating: autograder/requirements.txt  \n",
      "   creating: autograder/tests/\n",
      "  inflating: autograder/tests/q5.py  \n",
      "  inflating: autograder/tests/q1.py  \n",
      "  inflating: autograder/tests/q4.py  \n",
      "  inflating: autograder/tests/q3.py  \n",
      "  inflating: autograder/tests/q2.py  \n",
      "   creating: autograder/files/\n",
      " extracting: autograder/files/test-df.csv  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "unzipped = subprocess.run([\"unzip\", \"autograder.zip\", \"-d\", \"autograder\"], stdout=PIPE, stderr=PIPE)\n",
    "print(unzipped.stdout.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['setup.sh', 'requirements.txt', 'run_autograder', 'tests', 'files']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"autograder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relative Imports on Gradescope\n",
    "\n",
    "Because of the way that the Gradescope autograder is set up, our script must change relative import syntax in order to ensure that the necessary files are loaded. **Because we cannot differentiate between package imports and relative imports, `otter gen` automatically assumes that if you are importing a .py file that it is called `utils.py`.** The regex used to change the import syntax will _only_ change the syntax if you're using the import statment\n",
    "\n",
    "```python\n",
    "from utils import *\n",
    "```\n",
    "\n",
    "For this reason, if you have any functions you need in a file that is going to be imported, _make sure that it is called `utils.py`._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
